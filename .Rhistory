# Submit the request using the configured session
response <- httr::GET(
url,
httr::progress(),
# httr::add_headers(`User-Agent` = "Mozilla/5.0"),
httr::authenticate(username, password)
)
# Check for successful response
if (httr::status_code(response) == 200) {
# Save the file
content <- httr::content(response, as = "raw")
writeBin(content, paste0(outPath_ci,year,"/temp/",filename))
print(paste0("File downloaded successfully: ",fileNum))
} else {
stop(paste0("Failed to download the file: ",filename))
}
}, error = function(e) {
# Handle any errors here
print(paste("Error:", e$message, " ", filename))
})
filename_list <- c(filename_list,filename)
}
# combine four tif flies into a single file
raster1 <- raster::raster(paste0(outPath_ci,"/",year,"/temp/",filename_list[1]))
raster2 <- raster::raster(paste0(outPath_ci,"/",year,"/temp/",filename_list[2]))
raster3 <- raster::raster(paste0(outPath_ci,"/",year,"/temp/",filename_list[3]))
raster4 <- raster::raster(paste0(outPath_ci,"/",year,"/temp/",filename_list[4]))
raster_list <- list(raster1, raster2, raster3, raster4)
merged_raster <- raster::merge(raster1, raster2, raster3, raster4)
raster::writeRaster(merged_raster,
filename = paste0(outPath_ci,year,"/",stringr::str_sub(filename, start = 1, end = 8)),
format = "GTiff", overwrite = TRUE)
}
library(httr)
session <- function(username, password) {
httr::authenticate(username, password)
}
password <- "Cosmetic88&&" # You need to provide your actual password here
my_session <- session(username, password)
url <- "https://oceandata.sci.gsfc.nasa.gov/getfile/L2024053.L3m_DAY_CYAN_CI_cyano_CYAN_CONUS_300m_1_1.tif"
response <- GET(url, authenticate(username, password))
# Check if the request was successful
if (http_status(response)$category == "Success") {
# Save the content to a file
content <- content(response, as = "raw")
writeBin(content, "downloaded_file.tif")
cat("Download complete.")
} else {
cat("Failed to download. HTTP status code:", http_status(response)$status_code)
}
library(httr)
session <- function(username, password) {
httr::authenticate(username, password)
}
username <- "ygrund"
password <- "Cosmetic88&&" # You need to provide your actual password here
my_session <- session(username, password)
url <- "https://oceandata.sci.gsfc.nasa.gov/getfile/L2024053.L3m_DAY_CYAN_CI_cyano_CYAN_CONUS_300m_1_1.tif"
response <- GET(url, authenticate(username, password))
# Check if the request was successful
if (http_status(response)$category == "Success") {
# Save the content to a file
content <- content(response, as = "raw")
writeBin(content, "downloaded_file.tif")
cat("Download complete.")
} else {
cat("Failed to download. HTTP status code:", http_status(response)$status_code)
}
library(curl)
username <- "ygrund"
password <- "Cosmetic88&&" # You need to provide your actual password here
# Create a handle with authentication
handle <- new_handle(
userpwd = paste0(username, ":", password),
httpauth = 1L
)
url <- "https://oceandata.sci.gsfc.nasa.gov/getfile/L2024053.L3m_DAY_CYAN_CI_cyano_CYAN_CONUS_300m_1_1.tif"
# Perform the request
req <- curl_fetch_memory(url, handle = handle)
# Check if the request was successful
if (req$status_code == 200) {
# Save the content to a file
writeBin(req$content, "downloaded_file.tif")
cat("Download complete.")
} else {
cat("Failed to download. HTTP status code:", req$status_code)
}
username <- "ygrund"
password <- "Cosmetic88&&" # You need to provide your actual password here
url <- "https://oceandata.sci.gsfc.nasa.gov/getfile/L2024053.L3m_DAY_CYAN_CI_cyano_CYAN_CONUS_300m_1_1.tif"
output_file <- "downloaded_file.tif"
# Use the username and password in the URL
download.file(url, destfile = output_file, method = "libcurl", extra = paste0("--user ", username, ":", password))
# Check if the file has been downloaded
if (file.exists(output_file)) {
cat("Download complete.")
} else {
cat("Failed to download.")
}
url <- "https://oceandata.sci.gsfc.nasa.gov/getfile/L2024053.L3m_DAY_CYAN_CI_cyano_CYAN_CONUS_300m_2_1.tif"
output_file <- "downloaded_file.tif"
# Use the username and password in the URL
download.file(url, destfile = output_file, method = "libcurl", extra = paste0("--user ", username, ":", password))
# Check if the file has been downloaded
if (file.exists(output_file)) {
cat("Download complete.")
} else {
cat("Failed to download.")
}
library(httr)
# Define username and password
username <- "ygrund"
password <- "Cosmetic88&&"  # Replace XXXX with your actual password
# Define the URL
url <- "https://oceandata.sci.gsfc.nasa.gov/getfile/L2024053.L3m_DAY_CYAN_CI_cyano_CYAN_CONUS_300m_1_1.tif"
# Define custom headers for authentication
custom_headers <- add_headers("Authorization" = paste("Basic", enc2utf8(base64enc::base64encode(paste(username, password, sep = ":")))))
# Perform the GET request
response <- GET(url, custom_headers)
# Define custom headers for authentication
custom_headers <- add_headers("Authorization" = paste("Basic", enc2utf8(base64enc::base64encode(paste(username, password, sep = ":")))))
library(httr)
# Define username and password
username <- "ygrund"
password <- "Cosmetic88&&"  # Replace XXXX with your actual password
# Define the URL
url <- "https://oceandata.sci.gsfc.nasa.gov/getfile/L2024053.L3m_DAY_CYAN_CI_cyano_CYAN_CONUS_300m_1_1.tif"
# Define custom headers for authentication
custom_headers <- add_headers("Authorization" = paste("Basic", enc2utf8(base64enc::base64encode(paste(username, password, sep = ":")))))
# Define username and password
username <- "ygrund"
password <- "Cosmetic88&&"  # Replace XXXX with your actual password
# Define the URL
url <- "https://oceandata.sci.gsfc.nasa.gov/getfile/L2024053.L3m_DAY_CYAN_CI_cyano_CYAN_CONUS_300m_1_1.tif"
# Encode username and password
credentials <- base64enc::base64encode(paste0(username, ":", password))
# Create custom headers with authentication
headers <- c("Authorization" = paste("Basic", credentials))
# Perform the GET request with custom headers
response <- GET(url, add_headers(headers))
library(httr)
# Define username and password
username <- "ygrund"
password <- "Cosmetic88&&"  # Replace XXXX with your actual password
# Define the URL
url <- "https://oceandata.sci.gsfc.nasa.gov/getfile/L2024053.L3m_DAY_CYAN_CI_cyano_CYAN_CONUS_300m_1_1.tif"
# Encode username and password
credentials <- base64enc::base64encode(paste0(username, ":", password))
library(httr)
library(base64enc)
# Define username and password
username <- "ygrund"
password <- "Cosmetic88&&"  # Replace XXXX with your actual password
# Define the URL
url <- "https://oceandata.sci.gsfc.nasa.gov/getfile/L2024053.L3m_DAY_CYAN_CI_cyano_CYAN_CONUS_300m_1_1.tif"
# Encode username and password
credentials <- paste0(username, ":", password)
credentials_encoded <- base64encode(charToRaw(credentials))
# Create custom headers with authentication
headers <- c("Authorization" = paste("Basic", credentials_encoded))
# Perform the GET request with custom headers
response <- GET(url, add_headers(headers))
# Check if the request was successful
if (http_status(response)$category == "Success") {
# Save the content to a file
content <- content(response, as = "raw")
writeBin(content, "downloaded_file.tif")
cat("Download complete.")
} else {
cat("Failed to download. HTTP status code:", http_status(response)$status_code)
}
library(httr)
# Define username and password
username <- "ygrund"
password <- "Cosmetic88&&"  # Replace XXXX with your actual password
# Define the URL with embedded username and password
url <- paste0("https://", username, ":", password, "@oceandata.sci.gsfc.nasa.gov/getfile/L2024053.L3m_DAY_CYAN_CI_cyano_CYAN_CONUS_300m_1_1.tif")
# Perform the GET request
response <- GET(url)
# Check if the request was successful
if (http_status(response)$category == "Success") {
# Save the content to a file
content <- content(response, as = "raw")
writeBin(content, "downloaded_file.tif")
cat("Download complete.")
} else {
cat("Failed to download. HTTP status code:", http_status(response)$status_code)
}
# Define the URL
url <- "https://oceandata.sci.gsfc.nasa.gov/getfile/L2024053.L3m_DAY_CYAN_CI_cyano_CYAN_CONUS_300m_1_1.tif"
# Perform the GET request
response <- GET(url)
# Inspect the response headers
response_headers <- headers(response)
print(response_headers)
library(httr)
library(dplyr)
# Function to create a custom session for authentication
session <- function(username, password) {
httr::authenticate(username, password)
}
# Define username and password
username <- "ygrund"
password <- "Cosmetic88&&"
# Create the session
my_session <- session(username, password)
# Define the URL prefix
url_prefix <- "https://oceandata.sci.gsfc.nasa.gov/getfile/"
# Read dates
dates <- readxl::read_excel("./data/calendar-dates.xlsx")
# Filter dates
day_end <- dates %>%
dplyr::filter(as.POSIXlt(Date) == as.POSIXlt(Sys.Date()-1)) %>%
dplyr::pull(CyAN_File_NUM)
file_num <- dates %>%
dplyr::filter(as.numeric(CyAN_File_NUM) >= as.numeric(day_start) &
as.numeric(CyAN_File_NUM) <= as.numeric(day_end))
tiles <- c("1_1", "1_2", "2_1", "2_2")
outPath_ci <- "//deqhq1/WQ-Share/Harmful Algal Blooms Coordination Team/Satellite data/CyAN_Data_V5/Sentinel-3/CI_cyano/raw/"
for(fileNum in file_num$CyAN_File_NUM) {
year <- file_num %>%
dplyr::filter(CyAN_File_NUM == fileNum) %>%
dplyr::pull(Year)
folder_path <- paste0(outPath_ci, year, "/temp/")
if(!file.exists(folder_path)) {
dir.create(folder_path, showWarnings = TRUE, recursive = FALSE)
}
for(tile in tiles) {
url <- paste0(url_prefix, "L", fileNum, ".L3m_DAY_CYAN_CI_cyano_CYAN_CONUS_300m_", tile, ".tif")
filename <- sub(".*/", "", url)
tryCatch({
# Submit the request using the configured session
response <- httr::GET(
url,
httr::progress(),
httr::authenticate(username, password)
)
# Check for successful response
if (httr::status_code(response) == 200) {
# Save the file
content <- httr::content(response, as = "raw")
writeBin(content, paste0(outPath_ci, year, "/temp/", filename))
print(paste0("File downloaded successfully: ", fileNum))
} else {
stop(paste0("Failed to download the file: ", filename))
}
}, error = function(e) {
# Handle any errors here
print(paste("Error:", e$message, " ", filename))
})
}
}
paste0(url_prefix, "L", fileNum, ".L3m_DAY_CYAN_CI_cyano_CYAN_CONUS_300m_", tile, ".tif")
day_start <- "2024054"
library(httr)
library(dplyr)
# Function to create a custom session for authentication
session <- function(username, password) {
httr::authenticate(username, password)
}
# Define username and password
username <- "ygrund"
password <- "Cosmetic88&&"
# Create the session
my_session <- session(username, password)
dates <- readxl::read_excel("./data/calendar-dates.xlsx")
day_end <- dates %>% dplyr::filter(as.POSIXlt(Date) == as.POSIXlt(Sys.Date()-1)) %>% dplyr::pull(CyAN_File_NUM)
print(paste0("Day State: ",dates[which(dates$CyAN_File_NUM == day_start),]$Date, " | ",day_start))
print(paste0("Day End: ",dates[which(dates$CyAN_File_NUM == day_end),]$Date, " | ",day_end))
file_num <- dates %>% dplyr::filter(as.numeric(CyAN_File_NUM) >= as.numeric(day_start) &
as.numeric(CyAN_File_NUM) <= as.numeric(day_end))
tiles <- c("1_1","1_2","2_1","2_2")
outPath_ci <- "//deqhq1/WQ-Share/Harmful Algal Blooms Coordination Team/Satellite data/CyAN_Data_V5/Sentinel-3/CI_cyano/raw/"
for(fileNum in file_num$CyAN_File_NUM) {
# test: fileNum = "2024054"
year <- file_num %>% dplyr::filter(CyAN_File_NUM == fileNum) %>% dplyr::pull(Year)
filename_list <- list()
folder_path <- paste0(outPath_ci, year, "/temp/")
if(!file.exists(folder_path)) {dir.create(folder_path, showWarnings = TRUE, recursive = FALSE)}else{}
for(tile in tiles){
# test: tile = "1_1"
url <- paste0("https://oceandata.sci.gsfc.nasa.gov/getfile/L",fileNum,".L3m_DAY_CYAN_CI_cyano_CYAN_CONUS_300m_",tile,".tif")
filename <- sub(".*/", "", url)
tryCatch({
# Submit the request using the configured session
response <- httr::GET(
url,
httr::progress(),
# httr::add_headers(`User-Agent` = "Mozilla/5.0"),
httr::authenticate(username, password)
)
# Check for successful response
if (httr::status_code(response) == 200) {
# Save the file
content <- httr::content(response, as = "raw")
writeBin(content, paste0(outPath_ci,year,"/temp/",filename))
print(paste0("File downloaded successfully: ",fileNum))
} else {
stop(paste0("Failed to download the file: ",filename))
}
}, error = function(e) {
# Handle any errors here
print(paste("Error:", e$message, " ", filename))
})
filename_list <- c(filename_list,filename)
}
# combine four tif flies into a single file
raster1 <- raster::raster(paste0(outPath_ci,"/",year,"/temp/",filename_list[1]))
raster2 <- raster::raster(paste0(outPath_ci,"/",year,"/temp/",filename_list[2]))
raster3 <- raster::raster(paste0(outPath_ci,"/",year,"/temp/",filename_list[3]))
raster4 <- raster::raster(paste0(outPath_ci,"/",year,"/temp/",filename_list[4]))
raster_list <- list(raster1, raster2, raster3, raster4)
merged_raster <- raster::merge(raster1, raster2, raster3, raster4)
raster::writeRaster(merged_raster,
filename = paste0(outPath_ci,year,"/",stringr::str_sub(filename, start = 1, end = 8)),
format = "GTiff", overwrite = TRUE)
}
# Download data from OceanColor site
day_start <- "2024054"
# Path ----
baseurl <- "https://oceancolor.gsfc.nasa.gov/CYAN/OLCI/"
extract_base <- "//deqhq1/WQ-Share/Harmful Algal Blooms Coordination Team/Satellite data/CyAN_Data_V5/Sentinel-3/CI_cyano/raw/"
# Data an layers ----
dates <- readxl::read_excel("./data/calendar-dates.xlsx")
tiles <- c("1_1","1_2","2_1","2_2")
pattern <- paste0("_", paste(tiles, collapse = "|"), "\\.tif$")
year <- substr(day_start, 1, 4)
day_end <- dates %>% dplyr::filter(as.POSIXlt(Date) == as.POSIXlt(Sys.Date()-1)) %>% dplyr::pull(CyAN_File_NUM)
hab_days <- as.character(seq(day_start, day_end))
library(dplyr)
day_end <- dates %>% dplyr::filter(as.POSIXlt(Date) == as.POSIXlt(Sys.Date()-1)) %>% dplyr::pull(CyAN_File_NUM)
hab_days <- as.character(seq(day_start, day_end))
hab_days <- substr(hab_days, nchar(hab_days) - 2, nchar(hab_days))
hab_days_length <- length(hab_days)
print(paste0("Day State: ",dates[which(dates$CyAN_File_NUM == day_start),]$Date, " | ",day_start))
print(paste0("Day End: ",dates[which(dates$CyAN_File_NUM == day_end),]$Date, " | ",day_end))
print(paste0("Total Days | ",hab_days_length))
download_files <- paste0('L', year, hab_days, '.L3m_DAY_CYAN_CI_cyano_CYAN_CONUS_300m.tgz')
url <- paste0(baseurl, year, '/', hab_days, '/', download_files)
extract_path <- paste0(extract_base, year, "/temp/tgz/")
# Download data from OceanColor site
day_start <- "2024054"
# Path ----
baseurl <- "https://oceancolor.gsfc.nasa.gov/CYAN/OLCI/"
outPath_ci <- "//deqhq1/WQ-Share/Harmful Algal Blooms Coordination Team/Satellite data/CyAN_Data_V5/Sentinel-3/CI_cyano/raw/"
# Data an layers ----
dates <- readxl::read_excel("./data/calendar-dates.xlsx")
tiles <- c("1_1","1_2","2_1","2_2")
pattern <- paste0("_", paste(tiles, collapse = "|"), "\\.tif$")
year <- substr(day_start, 1, 4)
day_end <- dates %>% dplyr::filter(as.POSIXlt(Date) == as.POSIXlt(Sys.Date()-1)) %>% dplyr::pull(CyAN_File_NUM)
hab_days <- as.character(seq(day_start, day_end))
hab_days <- substr(hab_days, nchar(hab_days) - 2, nchar(hab_days))
hab_days_length <- length(hab_days)
print(paste0("Day State: ",dates[which(dates$CyAN_File_NUM == day_start),]$Date, " | ",day_start))
print(paste0("Day End: ",dates[which(dates$CyAN_File_NUM == day_end),]$Date, " | ",day_end))
print(paste0("Total Days | ",hab_days_length))
download_tgz <- paste0('L', year, hab_days, '.L3m_DAY_CYAN_CI_cyano_CYAN_CONUS_300m.tgz')
download_tgz
url <- paste0(baseurl, year, '/', hab_days, '/', download_tgz)
url
extract_path <- paste0(outPath_ci, year, "/temp/tgz/")
extract_path
folder_path
folder_path <- paste0(outPath_ci, year, "/temp/")
extract_tgz_path <- paste0(outPath_ci, year, "/temp/tgz/")
extract_tgz_path <- paste0(outPath_ci, year, "/temp/tgz/")
extract_tgz_path
folder_path <- paste0(outPath_ci, year, "/temp/")
folder_path
folder_path <- paste0(outPath_ci, year, "/temp/")
i=1
# test: i=1
cat(url[i], "\n")
download_tgz_path
download_tgz_path <- paste0(outPath_ci, year, "/temp/tgz/")
download_tgz_path
download_tgz
download_folder <- paste0(download_tgz_path, substr(download_tgz[i],1, nchar(download_tgz[i]) - 4))
download_folder
downloaded_files <- list.files(download_folder, full.names = TRUE)
tile_files_from <- grep(pattern, downloaded_files, value = TRUE)
tile_files_from
downloaded_files
download_folder
download_tgz
substr(download_tgz[i],1, nchar(download_tgz[i]) - 4)
downloaded_files
tile_files_from
paste0("/tgz/",substr(download_tgz[i],1, nchar(download_tgz[i]) - 4))
tile_files_to <- grep(paste0("/tgz/",substr(download_tgz[i],1, nchar(download_tgz[i]) - 4)), tile_files_from)
tile_files_to
tile_files_to <- grep(paste0("/tgz/",substr(download_tgz[i],1, nchar(download_tgz[i]) - 4)), "", tile_files_from)
tile_files_to
paste0("/tgz/",substr(download_tgz[i],1, nchar(download_tgz[i]) - 4))
tile_files_from
i=1
# test: i=1
cat(url[i], "\n")
utils::download.file(url[i], destfile = paste0(download_tgz_path, download_tgz[i]))
download_folder <- paste0(download_tgz_path, substr(download_tgz[i],1, nchar(download_tgz[i]) - 4))
download_folder
downloaded_files
downloaded_files <- list.files(download_folder, full.names = TRUE)
tile_files_from <- grep(pattern, downloaded_files, value = TRUE)
tile_files_from
for (file in tile_files_from) {
tile_files_to <- grep(paste0("/tgz/",substr(download_tgz[i],1, nchar(download_tgz[i]) - 4)), "", file)
file.copy(from = file, to = tile_files_to)
}
file
# test: file = "//deqhq1/WQ-Share/Harmful Algal Blooms Coordination Team/Satellite data/CyAN_Data_V5/Sentinel-3/CI_cyano/raw/2024/temp/tgz/L2024054.L3m_DAY_CYAN_CI_cyano_CYAN_CONUS_300m/L2024054.L3m_DAY_CYAN_CI_cyano_CYAN_CONUS_300m_1_1.tif"
tile_files_to <- grep(paste0("/tgz/",substr(download_tgz[i],1, nchar(download_tgz[i]) - 4)), "", file)
tile_files_to
paste0("/tgz/",substr(download_tgz[i],1, nchar(download_tgz[i]) - 4))
paste0("/tgz/",substr(download_tgz[i],1, nchar(download_tgz[i]) - 4))
file
# test: file = "//deqhq1/WQ-Share/Harmful Algal Blooms Coordination Team/Satellite data/CyAN_Data_V5/Sentinel-3/CI_cyano/raw/2024/temp/tgz/L2024054.L3m_DAY_CYAN_CI_cyano_CYAN_CONUS_300m/L2024054.L3m_DAY_CYAN_CI_cyano_CYAN_CONUS_300m_1_1.tif"
tile_files_to <- gsub(paste0("/tgz/",substr(download_tgz[i],1, nchar(download_tgz[i]) - 4)), "", file)
tile_files_to
for (file in tile_files_from) {
tile_files_to <- gsub(paste0("/tgz/",substr(download_tgz[i],1, nchar(download_tgz[i]) - 4)), "", file)
file.copy(from = file, to = tile_files_to)
}
for (file in tile_files_from) {
tile_files_to <- gsub(paste0("/tgz/",substr(download_tgz[i],1, nchar(download_tgz[i]) - 4)), "", file)
file.copy(from = file, to = tile_files_to)
}
# Download data from OceanColor site
day_start <- "2024054"
# Path ----
baseurl <- "https://oceancolor.gsfc.nasa.gov/CYAN/OLCI/"
outPath_ci <- "//deqhq1/WQ-Share/Harmful Algal Blooms Coordination Team/Satellite data/CyAN_Data_V5/Sentinel-3/CI_cyano/raw/"
# Data an layers ----
dates <- readxl::read_excel("./data/calendar-dates.xlsx")
tiles <- c("1_1","1_2","2_1","2_2")
pattern <- paste0("_", paste(tiles, collapse = "|"), "\\.tif$")
year <- substr(day_start, 1, 4)
day_end <- dates %>% dplyr::filter(as.POSIXlt(Date) == as.POSIXlt(Sys.Date()-1)) %>% dplyr::pull(CyAN_File_NUM)
hab_days <- as.character(seq(day_start, day_end))
hab_days <- substr(hab_days, nchar(hab_days) - 2, nchar(hab_days))
hab_days_length <- length(hab_days)
print(paste0("Day State: ",dates[which(dates$CyAN_File_NUM == day_start),]$Date, " | ",day_start))
print(paste0("Day End: ",dates[which(dates$CyAN_File_NUM == day_end),]$Date, " | ",day_end))
print(paste0("Total Days | ",hab_days_length))
download_tgz <- paste0('L', year, hab_days, '.L3m_DAY_CYAN_CI_cyano_CYAN_CONUS_300m.tgz')
url <- paste0(baseurl, year, '/', hab_days, '/', download_tgz)
download_tgz_path <- paste0(outPath_ci, year, "/temp/tgz/")
folder_path <- paste0(outPath_ci, year, "/temp/")
library(dplyr)
# Download data from OceanColor site
day_start <- "2024054"
# Path ----
baseurl <- "https://oceancolor.gsfc.nasa.gov/CYAN/OLCI/"
outPath_ci <- "//deqhq1/WQ-Share/Harmful Algal Blooms Coordination Team/Satellite data/CyAN_Data_V5/Sentinel-3/CI_cyano/raw/"
# Data an layers ----
dates <- readxl::read_excel("./data/calendar-dates.xlsx")
tiles <- c("1_1","1_2","2_1","2_2")
pattern <- paste0("_", paste(tiles, collapse = "|"), "\\.tif$")
year <- substr(day_start, 1, 4)
day_end <- dates %>% dplyr::filter(as.POSIXlt(Date) == as.POSIXlt(Sys.Date()-1)) %>% dplyr::pull(CyAN_File_NUM)
hab_days <- as.character(seq(day_start, day_end))
hab_days <- substr(hab_days, nchar(hab_days) - 2, nchar(hab_days))
hab_days_length <- length(hab_days)
print(paste0("Day State: ",dates[which(dates$CyAN_File_NUM == day_start),]$Date, " | ",day_start))
print(paste0("Day End: ",dates[which(dates$CyAN_File_NUM == day_end),]$Date, " | ",day_end))
print(paste0("Total Days | ",hab_days_length))
download_tgz <- paste0('L', year, hab_days, '.L3m_DAY_CYAN_CI_cyano_CYAN_CONUS_300m.tgz')
url <- paste0(baseurl, year, '/', hab_days, '/', download_tgz)
download_tgz_path <- paste0(outPath_ci, year, "/temp/tgz/")
for (i in 1:hab_days_length) {
# test: i=1
cat(url[i], "\n")
utils::download.file(url[i], destfile = paste0(download_tgz_path, download_tgz[i]))
utils::untar(paste0(download_tgz_path, download_tgz[i]), exdir = download_tgz_path)
download_folder <- paste0(download_tgz_path, substr(download_tgz[i],1, nchar(download_tgz[i]) - 4))
downloaded_files <- list.files(download_folder, full.names = TRUE)
tile_files_from <- grep(pattern, downloaded_files, value = TRUE)
for (file in tile_files_from) {
tile_files_to <- gsub(paste0("/tgz/",substr(download_tgz[i],1, nchar(download_tgz[i]) - 4)), "", file)
file.copy(from = file, to = tile_files_to)
}
}
tiles <- paste0("_", paste(c("1_1","1_2","2_1","2_2"), collapse = "|"), "\\.tif$")
tiles
download_tgz_path
download_tgz
download_folder
downloaded_files
tile_files_from
download_tgz_path
download_tgz[i]
download_folder
download_folder <- sub("\\.tgz$", "", file.path(download_tgz_path, download_tgz[i]))
download_folder
tile_files_to <- gsub("/tgz/", "", sub("\\.tgz$", "", file.path(download_tgz_path, download_tgz[i])))
tile_files_to <- gsub(paste0("/tgz/",substr(download_tgz[i],1, nchar(download_tgz[i]) - 4)), "", file)
tile_files_to
download_folder
download_tgz_path
tile_files_to <- gsub("/tgz/", "", download_folder)
tile_files_to
tile_files_to <- gsub(paste0("/tgz/",substr(download_tgz[i],1, nchar(download_tgz[i]) - 4)), "", file)
tile_files_to
download_folder
downloaded_files
tile_files_from
file[i]
tile_files_from[1]
download_folder[1]
downloaded_files[1]
download_tgz[i]
